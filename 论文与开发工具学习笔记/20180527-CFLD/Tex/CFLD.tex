% 设置编码，编码为UTF-8编码，字号大小12pt
\documentclass[UTF8, 12pt]{ctexart}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{titlesec}{\tiny}
\usepackage{amsmath}
% 定义
\newtheorem{theorem}{Theorem}[section]
% 控制图片的位置，让图片紧紧的跟住文字，只需写\begin{figure}[H]
\usepackage{float}
% 使用文献引用
\usepackage{cite}

% 使用算法排版模块
\usepackage{algorithm}  
\usepackage{algorithmic} 

% 设置文本格式，文本间距等，具体参考如下：
% left=2cm, right=2cm, top=2.5cm,bottom=1.5cm
\geometry{a4paper, centering, scale=0.81}
\newtheorem{thm}{定义}

\begin{document}
\title{\heiti 监督学习算法初探}
\author{\kaishu 尹卓\\北京工业大学\\MichaelYin777@outlook.com\\}
\date{\today}
\maketitle

% 增加目录
\tableofcontents
\newpage

\section{引言}
现代社会进入了数据爆炸的年代。每秒钟有几十小时的视频数据被上传到互联网上，上万条微博被发出。如此巨量的数据，要求我们使用能够自动分析数据的方法，来替代人工的检视，这也就是\emph{机器学习(Machine learning)}所想要做到的。\emph{机器学习(Machine learning)}被定义为一系列的方法，能够自动的检测数据中的\emph{模式(Patterns)}，随后能够使用发现的模型预测未来的发展，或者是做出其他的决策\cite{robert2014machine}。本文旨在以尽量少的“数学”的基础上，阐述机器学习里面临的一些挑战，并简要介绍一些机器学习算法的思想与精髓，以供对于机器学习没有任何了解的同学对于机器学习有直观上的认识。

\section{学习算法}
\subsection{学习算法的种类}
机器学习算法，一般被分为三种：\emph{监督学习}，\emph{无监督学习}和\emph{强化学习}。这里需要事先规定后面将会使用到的数学符号：我们定义$D=\{(x^{(1)}, y^{(1)}),...,(x^{(m)}), y^{(m)}\}$代表一个数据集，$\{x^{(i)},y^{(i)}\}$代表数据集里的第$i$个样本与其对应的输出$y^{(i)}$，$x_{j}$代表数据集的第$j$个特征，并且数据本身具有$m$个样本，$n$个特征，所有的$x_{j}^{(i)}$组合起来可以构成一个矩阵，记做$X$矩阵。监督学习目标是将输入$X$，通过从数据中学习，映射到输出$y$上面去。当$y$是离散的类标签的时候（比如说通过人的身高体重，判断是男人还是女人），这样的任务被叫做\emph{分类(Classification)}或者叫做\emph{模式识别(Pattern recognition)}；当输出的$y$是连续的实数值的时候，任务又被叫做\emph{回归(Regression)}。第二种类型的学习叫做\emph{无监督学习(Unsupervised learning)}，有时候也叫\emph{知识发现(Knowledge discovery)}。无监督学习里，拥有的只有数据$X$，并没有对应的类标记，学习算法被寄希望于自己去找到数据中的一些“有意思”的模式，或者说是规律。如图1所示，左边是二维情况下的数据，可以很明显的看出，数据呈现出内圈和外圈两种形态，聚类算法准确的识别出了内圈和外圈对应的样本点。

\begin{figure}[H]
	\centering
	\begin{tabular}{ccc}
		\includegraphics[width=0.35\linewidth]{..//Plots//noisy_circleDataset.pdf}  & 
		\includegraphics[width=0.35\linewidth]{..//Plots//noisy_circleClusteringResults.pdf} &\\
		(a) & (b)\\
	\end{tabular}
	\caption{(a)circle数据集 (b)聚类算法识别出来的“模式”}
	\label{Fig:1}
	\vspace{-0.5em}
\end{figure}

对于最后一种机器学习方式，也就是\emph{强化学习(Reinforcement learning)}，平时比较少见。这种学习算法通常在学习行为的时候使用（想象婴儿学习如何走路），当学习这些行为时，都对应有相应的奖励与惩罚，做对了就奖励，做错了就惩罚。值得注意的是，在2016年大放异彩的围棋机器人Alpha Go，就是深度学习和强化学习的结合成果，而现在非常火热的深度学习，则是既有监督学习的成分在里面，也有无监督学习在发挥作用。

\subsection{一些基本概念}
这里简要而不拘谨于严苛的定义的介绍一下机器学习里面一些重要的概念。当提到机器学习时，其实追根溯源，无非是想学习出一些参数，让输入数据结合这些参数，可以准确的获取到输出，这就是机器学习的目的。我们对于数据服从的规律假设，称之为“模型”，决定模型的其实是一系列的模型参数。实际上，这些参数就是对数据本身规律的反映，若是算法真正学习到了数据中的潜在规律，那么当给定输入时，就会获得准确的输出。
同时应当明确，当对于数据进行学习时，并不是说机器学习算法在数据上准确率越高越好。换言之，对于一组数据，若是机器学习算法在学习了这组数据的规律之后，在这组数据上实现了100\%的分类正确率，或者是回归的\emph{均方误差(Mean squared error)}几乎为0，这些都并不说明任何问题，因为很有可能，这个算法已经\emph{过拟合(Overfitting)}了。
\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{..//Plots//overfitting.pdf}
	\caption{回归算法中的过拟合与欠拟合现象}
	\label{Fig:0}
	\vspace{-0.5em}
\end{figure}

这里举出上图的例子来说明回归时的过拟合与欠拟合问题。数据的真实规律如橙线所示，样本点是真实曲线加上噪声采集出来的一些点。我们尝试去建立一个回归模型，通过拟合数据来寻找数据中的真实规律。左图中，使用了线性模型对于数据进行拟合，可以看到效果非常的差，因为数据本质的规律并不是线性的。由于模型拟合能力有限，所以会出现模型难以逼近数据的真实规律的现象，这种现象被称为\emph{欠拟合(Underfitting)}。当使用非常复杂的模型来拟合这组数据，模型在每一个样本点上都做到了误差尽量的小，然而实际学习出来的曲线和真实曲线相距胜远。这种模型过度对数据学习，过于强调在数据上的低误差，而导致未能学习到真实规律的现象被称之为\emph{过拟合(Overfitting)}。选择合适的模型参数就显得至关重要。这样就引出了对于数据的划分，一般会将数据划分为三个集合：
\begin{enumerate}
	\item 训练集：学习算法利用训练集进行训练。
	\item 验证集：学习算法利用验证集，来选择模型复杂度的参数，防止过拟合和欠拟合的现象。
	\item 测试集：测试集被单独划分出来，是因为希望学习算法在选择好参数并且训练好之后，模型设计者可以得知它在没有“见过”的数据集上的表现（错误率或者均方误差）大概是什么样的。
\end{enumerate}

这样，我们就既可以防止过拟合欠拟合的现象的发生，又可以对训练好的算法在没有见过的数据上的表现有一个评估结果。
最后需要注意的，其实是两条哲学道理。第一条是所谓的\emph{天下没有免费的午餐(No free lunch theory)}，这条定理可以译作：没有任何的学习算法，可以在所有任务上都能做的好。这点可以严格的被统计学习理论证明出来。也就是说，脱离具体问题来空泛的谈论“某一算法很好”，是没有任何意义的，比如说图像识别领域，深度学习算法表现非常出色，但是在数据挖掘领域，却常不如传统的一些机器学习算法。所以一定要具体问题具体分析。第二条是\emph{奥卡姆的剃刀(Occam's Razor)}，译作：能简即简。这条定理主张的是若是某项任务能用一个复杂的模型和一个不那么复杂的模型都能达到相似的效果，那么优先选择简单的模型，因为复杂的模型虽然威力巨大，但是可能会付出过拟合和计算量增加的代价。

\section{测试数据集}
在本文中，我们使用两组数据集，以方便读者对于分类器的效果有直观的感受。第一组数据集是人造的三个数据集\cite{pedregosa2011scikit}，每个数据集包含两个特征，是分类数据集，人造数据集的分布情况如图所示：
\begin{figure}[H]
	\centering
	\begin{tabular}{ccc}
		\includegraphics[width=0.32\linewidth]{..//Plots//MoonDataset.pdf}  & 
		\includegraphics[width=0.32\linewidth]{..//Plots//CircleDataset.pdf} &
		\includegraphics[width=0.31\linewidth]{..//Plots//LinearlyDataset.pdf} \\
		(a) & (b) & (c)\\
	\end{tabular}
	\caption{(a)circle数据集聚类结果 (b)moon数据集聚类结果 (c)blobs数据集聚类结果}
	\label{Fig:2}
	\vspace{-0.5em}
\end{figure}

人造的三个数据集都属于\emph{线性不可分(Not linearly separable)}的情形，也就是说找不到一根直线，能够100\%正确的将两堆样本分开。同时数据集(a)与(b)可以看出，必须使用一根弯弯曲曲的曲线，才能将两堆数据相对比较正确的分开。

第二组数据是来自Kaggle数据挖掘竞赛网站的人力资源数据集，包含9个输入特征，输出变量是雇员离职与否。如下表所示，这是人力资源数据集的前4行数据，表头依次代表：对工作的满意程度(sLeavel)，上次评估的分数(lastEval)，手上的项目数(projNums)，每月工作时间(mHours)，每天在公司时间(cTime)，工作事故数(accident)，过去5年是否升职(promote)，工作性质(job)，薪水程度(salary)，离职与否(left)。我们希望借助前面的一系列特征，判断员工是不是会离职。

\begin{table}[H]
	\centering
	\label{table1}
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
		\hline
		sLevel & lastEval & projNums & mHours& cTime & accident & promote & job & salary & left\\
		\hline
		0.38 & 0.53 & 2 & 157 & 3 & 0 & 0 & sales & low & 1\\
		0.8 & 0.86 & 5 & 262 & 6 & 0 & 0 & sales & medium & 1\\
		0.11 & 0.88 & 7 & 272 & 4 & 0 & 0 & sales & medium & 1\\
		0.72 & 0.87 & 5 & 223 & 5 & 0 & 0 & sales & low & 1\\
		\hline
	\end{tabular}
	\caption{人力资源数据集前4行}
\end{table}

在这里举第一个例子的目的，是为了让读者对于分类器的分类效果产生一个直观的感受；对于第二个真实数据集，我们想要说明的是在从数据中学习的场景当中最常遇见的一些挑战，这里简要列举了几点：
\begin{enumerate}
	\item 数据缺失。现实当中采集回来的数据，或多或少会有些缺失值，比如说人力资源数据，有些人可能选择性的填写了表格的其中几项，导致数据不完整。对于这种情况，常用的做法有使用该特征的均值或者众数来填补缺失值（缺失不多的情况之下），或者使用专门的算法来处理这个问题，这里不再展开说明。
	\item 样本不均衡。从不均衡数据中学习一直是具有挑战性的一项工作。这里指的不均衡数据是指标签中，某些类的标签占绝大多数，而关注的类标签只占极少数。比方说需要建立一个诊断某种病的分类器，给分类器输入一些病人的特征，输出是病人是否患有该种疾病。人群中患有该种病的人毕竟是极少数，导致人为的判断每一个病人都不患这种病，就可以实现99.99\%的正确率，但是这样的分类器是无效的。对于这种情况，正确率这个指标就发挥不了作用了，我们需要考虑其他的评价学习器的指标，以及借助一些其他的算法。
	\item 样本错误。样本错误也是一个常见的问题，比如人力资源数据集中，某人后来离职了，但是标签却是他没有离职，再比如说，一起交通事故里，出现驾驶员-10岁之类的。前者在实际的问题中非常难被识别出来，后者可以通过实现检视每一个特征的分布情况，来区分出异常的数据。
\end{enumerate}

\section{Logistic Regression}
这里要介绍的第一个算法，叫做\emph{逻辑斯蒂回归(Logistic regression)}，简称逻辑回归。逻辑回归，名字里有“回归”二字，其实它是一个分类算法。这里，需要使用一点点数学来说明逻辑回归到底怎么“work”。

首先，假设我们的模型是：
\begin{equation}
	h_{w}(x) = \frac{1}{1+e^{-(w_{0}x_{0}+w_{1}x_{1}+...+w_{n}x_{n})}}
\end{equation}

这里$w$是模型的参数，是想要通过从数据中“学习”得到的；$h_{w}(x)$代表了模型。为什么要这样假设呢？这是因为这里假设的其实是输入$X$与输出$y$之间满足线性的关系，比方说对于人力资源数据集，将各个特征分别乘以对应的系数，我们认为它们加起来的结果，表示员工离职的“确信度”。但是光组合起来是不够的，因为组合起来之后，计算出来的值是一个连续值，它的取值范围是$(-\infty, +\infty)$，而实际类标签的取值，也就是员工离职与否，却是一个离散的取值，也就是在集合$\{0, 1\}$内取值。因此，还需要找到一个函数，把刚才线性组合计算出来的连续的员工离职可能性的“确信度”，换算到一个离散的类标签上去。那么$sigmoid$函数就是一个很合适的选择。
\begin{figure}[H]
	\centering
	\includegraphics[width=0.40\linewidth]{..//Plots//sigmoidFcn.pdf}
	\caption{sigmoid函数图像}
	\label{Fig:3}
	\vspace{-0.5em}
\end{figure}

sigmoid函数的曲线如上图所示，它的公式是：
\begin{equation}
	y = \frac{1}{1+e^{-x}}
\end{equation}

可以看到，若是我们之前计算出来的离职的确信度非常高，$sigmoid$函数便会输出一个非常接近1的值；若是可信度比较低，则会输出一个非常接近0的值。我们利用模型计算在数据集每一个样本的“可信度”，乘以实际的标签，然后将他们加起来，作为我们的模型在整个数据集上的效果\cite{ng2000cs229}，也就是下面这个公式：
\begin{equation}
	J(w) = \frac{1}{m} \sum_{i=1}^{m} { -y^{(i)}\log(h_{w}(x^{(i)})) - (1-y^{(i)})\log(1-h_{w}(x^{(i)})) }
\end{equation}

对于第$i$个样本而言，当我们的输入$x^{(i)}$进入模型的时候，$h_{w}(x^{(i)})$将会有一个对应的输出，也就是模型输出。若是我们的模型能够反映数据内部的规律，那么模型计算的输出应该与类标签$y^{(i)}$应该是尽可能的是一致的，那么对于第$i$个样本上面式子$\sum$符号内部算出来的值应该是接近0的；若是不一致，那么$\sum$符号内部的式子将会算出一个非常大的正值来。求和之后，我们就度量了模型的输出和实际输出之间差别的总和。那么什么样的模型算是学到了数据里的规律呢？就是$h_{w}(x)$算出来的值与$y$的值的差别的总和越小越好，也就是$J(w)$的值越小就越好，自然我们只需要通过调整参数$w$来最小化$J(w)$就可以了。

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{..//Plots//LogisticRegression.pdf}
	\caption{测试数据集Logistic Regression结果的决策边界}
	\label{Fig:4}
	\vspace{-0.5em}
\end{figure}

上图便是我们的逻辑回归的\emph{决策边界(Decision boundry)}。底色的深浅代表模型的对于该区域的样本属于某一类的确信度。浅红色和浅蓝色的交界处就是决策边界。在决策边界红色一侧数据，将全部被判定为红色样本；蓝色一侧的样本，将会全部判定为蓝色样本，样本越靠近边界，越说明该样本处于该类的确信度越低；深蓝色样本代表我们的训练数据，浅蓝色的样本代表的我们的测试数据。由于逻辑回归属于线性分类器，也就是对特征进行线性组合来获取输出标签，所以只能获得线性的决策边界，这样就导致对于\emph{线性不可分(Not linearly separable)}的数据效果比较差，从图中我们也可以看出有不少分类错误的点。但是这仍然不影响逻辑回归是一种非常优秀和使用的算法。事实上，通过多项式特征的方式，逻辑回归也能画出非线性的决策边界，利用逻辑回归，我们可以对付绝大多数的分类问题。

在实际应用当中，对于损失函数$J(w)$，我们会看到这样的形式：
\begin{equation}
	J(w) = \frac{1}{m} \sum_{i=1}^{m} { -y^{(i)}\log(h_{w}(x^{(i)})) - (1-y^{(i)})\log(1-h_{w}(x^{(i)})) } + \frac{1}{n} \sum_{j=1}^{n} {w_{i}^{2}}
\end{equation}

这是我们视权值$w$的大小为我们的\emph{模型复杂度(Model complexity)}，我们希望对于模型的复杂度进行一定的约束，获得一个更加简单的模型，也就是权值更加小的模型，这就是\emph{正则化(Regularization)}的思想。逻辑回归的正则化可从参数的先验分布的角度和约束优化的角度来推导出来，由于需要比较多的数学知识，这里感兴趣的读者可参考文献\cite{robert2014machine}中的内容。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Support Vector Machine}
\emph{支持向量机(Support vector machine)}起源于上世纪90年代，其理论十分优雅完备，曾经风靡一时，至今仍然有着重要的应用。支持向量机起源于如何解决这样一个问题：对于平面上的两堆数据点，我们希望用一根直线将数据点完美的分开，哪根直线是最优的直线？这里我们生成了一个新的数据集来说明这个问题，如下图所示，便是一个\emph{线性可分(Linearly separable)}数据集。
\begin{figure}[H]
	\centering
	\begin{tabular}{ccc}
		\includegraphics[width=0.36\linewidth]{..//Plots//linearSeparable.pdf}  & 
		\includegraphics[width=0.36\linewidth]{..//Plots//linearSvmResults.pdf} &\\
		(a) & (b)\\
	\end{tabular}
	\caption{(a)线性可分数据集 (b)最优的决策边界}
	\label{Fig:5}
	\vspace{-0.5em}
\end{figure}

其实这里的“直线”，就是我们所谓的决策边界。直观来看，能够分开两堆点的直线会有无数多条。对于之前提到的逻辑回归算法，若是算法的初始迭代条件不一样，也会找到各种不同的决策边界。但是我们来考虑这样的情况：若是我们选择一根直线，在正确分割开两堆数据的前提之下，离两堆数据都尽可能的远，若是我们下次采集过来的数据，由于噪声或者是其他一些的原因，也许会离原来的采集那堆点比较的远，那么我们选择这样离两堆点尽量远的直线来分类的话，对于刚刚说的那种点能够分类正确的可能性就会提高，也就是说决策边界比较\emph{稳健(Robust)}。正如图(b)所示，灰色实线就是我们最优的决策边界。

支持向量机原理上非常明确，其所寻找的决策边界，就是在决策正确的前提之下，离两堆数据集尽可能远的直线或是超平面。但是，数学上想要寻找这样的直线，却不那么的简单。但这并不影响我们通俗的来阐述我们所要解决的数学问题。我们同样给定我们的模型：
\begin{equation}
	h_{w}(x) = w_{0}x_{0} + ... + w_{n}x_{n}
\end{equation}

对于上面的方程，$w$就是我们期望寻找的模型的参数，这和逻辑回归的假设非常的相似，都是线性模型的扩展。和逻辑回归通过sigmoid函数映射到$(0,1)$区间上去的方式不一样，支持向量机的输出的类标记是$\{-1, 1\}$。我们最终判断类标记的方式是：
\begin{equation}
	 sign(h_{w}(x))
\end{equation}

其中sign函数代表符号函数，其括号内部函数值大于0，则取1，否则取-1。我们定义样本点$i$到我们的决策边界的距离为：
\begin{equation}
	\hat{\gamma_{i}}= y^{(i)}w^{T}x^{(i)}
\end{equation}

其中$y^{(i)}$是我们的类标记，从集合$\{-1, 1\}$中取值。$w$是我们模型参数的向量形式，是一个含有$n+1$个变量的列向量，$x^{(i)}$对应于我们的第$i$个样本，是一个列向量。若是决策边界能够将数据都正确的分开，那么我们就可以在每一个样本按照上式计算一个正的“分数”，其实也就是样本点距离决策边界的距离。我们定义$\hat{\gamma}$为：
\begin{equation}
	\hat{\gamma} = \mathop{\min_{i=1,...,m}} \hat{\gamma_{i}} 
\end{equation}

也就是说我们对于每一个样本点计算这样的距离之后，挑选算出到决策边界最小的距离作为我们的$\hat{\gamma}$。那么我们给出支持向量机所需要解决的数学问题：
\begin{align}
	& \mathop{\max_{w}} \quad \hat{\gamma} \\
	& s.t. \quad y^{(i)}w^{T}x^{(i)} \geq \hat{\gamma}, \quad i = 1,...,m
\end{align}

这个式子其实就是对于之前的总结。我们希望通过调整参数$w$，使得到决策边界最近的距离$\hat{\gamma}$最大化；同时我们希望分类器对每一个数据点都能够正确的分类，也就是每一个数据点到决策边界的距离都会大于等于最小间距。这样，我们就可以将这些组合成一个约束优化问题，优化目标是距离最大化，约束条件是在每一个数据点上都做对。解这个优化问题，我们可以完美的解决线性可分数据集下的支持向量机问题。图6的(b)图就是支持向量机在线性可分的数据集上运行的结果。我们应当注意到，对于支持向量机而言，一定会存在一些点，对支持向量机参数的确定起了决定性的作用，这些点也就是距离决策边界最近的那些点，图6中的(b)图，我们可以清晰的看到这些点，我们把这些点叫做\emph{支持向量(Support vectors)}。若是我们去掉这些点，再训练一个支持向量机，那么决策边界就会大大的不同，这也是支持向量机对数据“敏感”的原因。

我们以上讨论了对于线性可分的情况下的支持向量机，但是这样是远远不够的，因为数据绝大部分是线性不可分的，如同我们的三个测试数据集一样，，对于三个测试数据集，线性可分的支持向量机不能获取正确的决策边界。我们需要对上述问题进行变换。考虑原始约束优化问题(9)和(10)，我们对参数$w$进行规范化，产生一个等价的优化问题：
\begin{align}
	& \mathop{\max_{w}} \quad \frac{\hat{\gamma}}{\Vert w \Vert} \\
	& s.t. \quad y^{(i)}w^{T}x^{(i)} \geq \hat{\gamma}, \quad i = 1,...,m
\end{align}

这里$\Vert · \Vert$代表$L_{2}$范数。由于我们的假设$h_{w}(x)$乘以某一常数，并不影响最终的$w$解，所以我们可以令$\hat{\gamma}=1$，同时最大化$1/\Vert w \Vert$的优化目标可以转化为最小化$\Vert w \Vert$，所以我们的优化目标变为了：
\begin{align}
	& \min_{w} \quad \frac{1}{2}{\Vert w \Vert}^{2} \\
	& s.t. \quad y^{(i)}w^{T}x^{(i)} \geq 1, \quad i = 1,...,m
\end{align}

以上是一个标准的\emph{凸二次规划问题}，可以用专门的软件来解。若是数据完全线性可分，则上式一定有解。但是若是我们想要我们的决策边界，不需要每一个数据都完美的分类正确，我们需要将条件放松一些：
\begin{align}
	\min_{w, \xi} & \quad \frac{1}{2}{\Vert w \Vert}^{2} + C\sum_{i=1}^{m}\xi_{i} \\
	s.t. & \quad y^{(i)}w^{T}x^{(i)} \geq 1 - \xi_{i}, \quad i = 1,...,m \\
	& \quad \xi_{i} \geq 0, \quad i = 1,...,m 
\end{align}

我们放松我们的约束条件，若是$i$点不能被决策边界正确的分类，我们让它算出来的分数加上一个正值$\xi_{i}$，使得算出来的分数仍然满足约束条件。同时我们希望我们的决策边界分类样本点时，所有需要加上的$\xi_{i}$才能对的样本点越少越好，代表我们让决策边界在尽可能多的点上做对，同时我们给其加以一个权重$C$，用于控制$\xi_{i}$的加和在我们优化目标中的重要程度。通过以上的变换，我们便可以解决线性不可分情况下的支持向量机问题。通过更加深入的分析，我们可以引入\emph{核方法(Kernel method)}进行对决策边界进行非线性变换，这里由于涉及到比较高深的数学知识，这里不再赘述，只演示算法效果。

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{..//Plots//svm.pdf}
	\caption{测试数据集RBF核的SVM分类的决策边界}
	\label{Fig:7}
	\vspace{-0.5em}
\end{figure}

我们在测试数据集上运行我们的非线性支持向量机算法。上图所示的就是改进以后的，利用RBF核函数的支持向量机分类结果。可以看到它的决策边界通过非线性变换，不再是原始定义中的线性形式。并且取得了非常好的效果。支持向量机理论优雅，效果出众，是一种非常优秀的算法。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Boosting算法}
\emph{提升(Boosting)}算法属于\emph{集成学习(Ensemble learning)}的大类中的一个分支。一般认为集成学习包括三种方法：\emph{装袋(Bagging)}，典型代表是\emph{随机森林(Random forest)}；\emph{提升(Boosting)}，典型代表是\emph{自适应提升(AdaBoost)}，\emph{梯度提升决策树(Gradient boosted decision tree)}；以及\emph{堆叠(Stacking)}，此方法没有典型的算法。提升方法基于这样一种思想：对于一个复杂的任务，将多个专家的意见综合起来判断，比任何一个专家单独判断好\cite{李航2012统计学习方法}。这里我们先阐述AdaBoost的算法思想，然后再提到GBDT的算法思想。同时，这里我们对于AdaBoost只讨论分类的情况，回归的情况不做讨论。

\subsection{AdaBoost算法}
对于我们的数据而言，标签在集合$\{1, -1\}$中取值。AdaBoost分类器开始于一个非常非常弱的分类器，其“弱”体现在：这个分类器能够将数据分成正例和反例，但是其效果只比随机猜测要好一点点。随后AdaBoost赋予新一轮迭代中上一轮弱分类器做错的样本更加高的权重，而降低上一轮弱分类器做对的样本。这可以看做一种从“错误”中进行学习的机制，我们新一轮的迭代强调之前的做错的样本，从上一轮的“失败”中吸取教训。随后不断的训练弱分类器，最后组合成最终的强分类器。AdaBoost分类器的计算过程如下图所示。其实本质上，AdaBoost也属于线性模型的一种推广，从这个角度来看，线性模型可以说是机器学习中应用最广泛的模型。

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{..//Plots//AdaBoostProcedure.pdf}
	\caption{AdaBoost算法的流程}
	\label{Fig:8}
	\vspace{-0.5em}
\end{figure}

这里，我们简明扼要的说明一下AdaBoost的算法流程，好让读者对于这种算法产生一个直观的认识。对于包含有$m$个样本的数据集$D=\{(x^{(1)}, y^{(1)}),...,(x^{(m)}), y^{(m)}\}$，若是我们想要训练一个包含$S$个基分类器的AdaBoost分类器，我们第一轮迭代的时候，首先初始化它的权值的分布:
\begin{equation}
	D_{1} = (w_{11}, w_{12},...,w_{1i},...,w_{1m}), \quad w_{1i} = \frac{1}{m}, \quad i = 1,...,m
\end{equation}

对于具有这样的权值分布的数据，我们训练一个分类器$G_{1}(x)$。通常AdaBoost训练的基分类器使用的是\emph{决策树桩(Decision stump)}。决策树桩就是单层的决策树，其决策方式是遍历数据的所有特征，计算每一个特征的\emph{基尼系数(Gini index)}，随后选择基尼系数最优的特征，对数据进行二分类。可以看出决策树桩是一个非常非常弱的分类器，因为它只使用了数据的一个特征做二分类。AdaBoost在训练基分类器时，与直接使用基尼系数进行切分不同，它选择\emph{加权错误(Weighted error)}最低的决策树桩作为该轮迭代的基分类器。随后计算$G_{1}(x)$在带权数据集$D_{1}$上的表现：
\begin{equation}
	e_{1} = \sum_{i=1}^{m} {w_{1i}I(G_{1}(x^{(i)}) \neq y^{(i)})}
\end{equation}

其中，$I(·)$代表\emph{指示函数(Indictor function)}，对于$I(G_{1}(x^{(i)}) \neq y^{(i)})$，若是$G_{1}(x^{(i)}) = y^{(i)}$则函数值取$1$，否则就取$0$。随后，计算此分类器的权重值$\alpha_{1}$：
\begin{equation}
	\alpha_{1} = \frac{1}{2} \log\frac{1-e_{1}}{e_{1}}
\end{equation}

这里取的对数是自然对数。这里可以这么来理解分类器的权重：若是分类器在带权数据集上的误差越小，那么$e_{1}$也就越小，其权重$\alpha_{1}$也就越大，也就是我们的这个基分类器在最终的模型里占的权重也就越大，因为它能够把带权的数据集做的很好。接下来我们会按照这一轮的错误情况，更新权值为：
\begin{align}
	& D_{2} = (w_{21}, w_{22},...,w_{2i},...,w_{2m}) \\
	& w_{2i} = \frac{w_{1i}}{Z_{1}} \exp{(-\alpha_{1}y^{(i)}G_{1}(x^{(i)}))}, \quad i = 1,..., m
\end{align}

这里我们可以看到AdaBoost给第一轮分类器做错的样本赋权的过程，反映在更新$w_{2i}$样本的权重值上面。无论是$x^{(i)}$是正样本还是负样本，若是我们第一轮分类器在样本点$i$上做对了，$G_{1}(x^{(i)})$的值与样本标签$y^{(i)}$的乘积应该是一个正值，计算出来的$\exp(-\alpha_{1}y^{(i)}G_{1}(x^{(i)}))$值应该是非常小的；若是在样本上做错了，那么$G_{1}(x^{(i)})$计算的值和样本标签符号不同，那么$\exp(-\alpha_{1}y^{(i)}G_{1}(x^{(i)}))$的指数值是一个整数，其样本权重经过指数运算被剧烈的放大，相当于实现了下一轮的赋予高权重的性质。其中$Z_{1}$是一个常数，计算方式如下：
\begin{equation}
	Z_{1} = \sum_{i=1}^{m} w_{1i}\exp{(-\alpha_{1}y^{(i)}G_{1}(x^{(i)}))}
\end{equation}

这样我们不停的重复之前提到的过程，若是想要训练$S$个基分类器，上述过程重复$S$次，最终我们的模型为各个分类器结果的加权组合：
\begin{equation}
	G(x) = sign(H(x)) = sign(\sum_{i=1}^{S} \alpha_{i}G_{i}(x))
\end{equation}

同时我们可以看到，由于每一次迭代，AdaBoost都任意挑选了数据带权错误率最小的特征，每次基分类器挑选的特征可能不一样，便相当于将空间切分成立非常多的区域。如下图所示：
\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{..//Plots//AdaBoost.pdf}
	\caption{AdaBoost分类器决策边界}
	\label{Fig:9}
	\vspace{-0.5em}
\end{figure}

这是我们的AdaBoost分类器运行在三个试验数据集上的结果，正是由于基分类器每一次切分的空间区域不尽相同，使得AdaBoost分类器具有了“非线性”分类器的特性。所以我们可以看到，其决策边界是一块一块的区域，这正是由于决策树桩的切分特性产生的。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Gradient boosted decision tree}
上一节我们介绍了Boosting的第一个算法：AdaBoost算法。AdaBoost的基分类器是决策树桩，每次分类的时候决策树桩选出加权错误率最低的一个特征对数据进行切分。当我们使用的基分类器从决策树桩，改为一棵完整的决策树的时候，AdaBoost分类器就变为了\emph{提升树(Boosting tree)}。在介绍提升树算法之前，我们先简要介绍一下\emph{梯度下降算法(Gradient descent)}。
梯度下降算法为的是渐进的找到函数$f(x)$的极值点。具体来说：\emph{梯度(Gradient)}是函数的一阶导数，代表函数在某点上升最快的方向。公式：
\begin{equation}
	x_{t+1} = x_{t} - \alpha_{t} f^{'}(x_{t})
\end{equation}

意为在第$t$次迭代时，我们的自变量的值是$x_{t}$，函数值为$f(x_{t})$，并且我们希望下一次迭代自变量的值$f(x_{t+1})<f(x_{t})$，由于$f^{'}(x_{t})$是函数在$x_{t}$处上升最快的方向，那么$-f^{'}(x_{t})$便是函数在$x_{t}$处下降最快的方向，这样式(25)相当于让自变量$x_{t}$朝着函数值下降最快的方向“迈出”了一步，到$x_{t+1}$，从而达到了渐进的降低函数值的目的，而参数$\alpha_{t}$代表着这一“步”需要迈多大，一般被称为\emph{学习率(Learning rate)}。

对于一般形式的提升模型来说，其过程与梯度下降的方式非常类似。对于梯度下降算法，若是迭代$T$次，最终的自变量的值变为$x_{T}$，而由(25)式可知：
\begin{equation}
	x_{T} = -\sum_{i=1}^{T} \alpha_{i}f^{'}(x_{i})
\end{equation}

$x_{i}$与$\alpha_{i}$代表第$i$次迭代的自变量值和学习率。类比梯度下降算法，观察提升模型的一般假设：
\begin{equation}
	H(x;P) = \sum_{s=0}^{S} {\beta_{s}h(x;\theta_{s})}
\end{equation}

其中$h(x;\theta_{s})$代表的是第$s$次迭代的基学习器，$\theta_{s}$代表基学习器的参数，$\beta_{s}$可以类比于下降的方向。我们定义$P=\{\theta_{s},\beta_{s}\}_{0}^{S}$代表上式所有参数的集合。这里可以看到提升模型和梯度下降算法有着非常相似的形式。当我们定义了一个\emph{损失函数(Loss function)}来度量模型输出与实际输出之间的差别时，我们记这个损失函数为$L(·,·)$，我们可以度量模型输出与实际输出之间的区别，我们的目的是：
\begin{equation}
	P^{*} = \operatorname*{argmin}\limits_{P}L(y,H(x;P))
\end{equation}

即寻找到最优的一组参数$P^{*}$，能够最小化式(28)的损失函数。但是不同于梯度下降算法对于具体变量的求导，梯度提升是对于“函数”进行求导\cite{chen2015xgboost}\cite{friedman2001greedy}：可以把每一个基学习器看做是一个函数，从而用损失函数对基学习器求偏导。具体来说，对于函数的梯度提升的第$m$次迭代，可以获得第$m$次迭代的梯度：
\begin{equation}
	g_{s}(x) = {[\frac{\partial L(y,F(x))}{\partial f(x)}]}_{F(x)=F_{s-1}(x)}
\end{equation}
其中：
\begin{equation}
	F_{s-1}(x) = \sum_{i=0}^{s-1}f_{i}(x)
\end{equation}
我们可以类似于梯度下降算法，让参数值“迈出”一步：
\begin{equation}
	F_{s}(x) = F_{s-1}(x) - \rho_{s}g_{s}(x)
\end{equation}
从而可以降低损失函数的值。参数$\rho_{s}$可以通过所谓的\emph{线搜索(Line search)}的方式来获得，具体来说就是优化：
\begin{equation}
	\rho_{s} = \operatorname*{argmin}\limits_{\rho}L(y,F_{s-1}-\rho g_{s})
\end{equation}
来获取最优的$\rho_{s}$。但是当数据是一堆的样本点：$D=\{(x^{(1)}, y^{(1)}),...,(x^{(m)}), y^{(m)}\}$时候，我们并不能获取真实的梯度值，只能有样本点计算出来的“梯度”：可以看做是真实梯度的近似，例如对于平方损失函数：
\begin{equation}
	{[\frac{\partial (y-H)^{2}/2}{\partial H}]}_{H=H_{s-1}} = \sum_{i=1}^{m} (y^{(i)} - H_{s-1}(x^{(i)}))
\end{equation}

这里的$H$便是之前提到的提升模型的假设，式(33)便是损失函数在$H=H_(s-1)$处的梯度的近似值。若是想要得到下一步的$h_{s}$，使得损失函数的值下降，不同于梯度下降算法计算一个最优的参数$\theta_{s}$降低损失函数，这里先在函数空间里拟合负梯度的近似值，找到函数空间里的负梯度的方向；然后再选择最优的学习率，“迈出”最大的一步。具体来说，在第$s$次迭代时，计算：
\begin{equation}
	{\hat{y}}^{(i)} = y^{(i)} - H_{m-1}(x^{(i)})
\end{equation}
该式被称为样本点$i$的\emph{残差(Residual)}，随后计算：
\begin{equation}
	(\theta_s,\beta_{s}) = \operatorname*{argmin}\limits_{\theta_s,\beta_{s}} \sum_{i=1}^{m}[{\hat{y}}^{(i)} - \beta_{s}h(x^{(i)};\theta_{s})]^2
\end{equation}
(35)式其实是计算了新一轮迭代的基学习器的参数$\{\beta_{s}, \theta_{s}\}$。随后类似于梯度下降算法，将新的参数更新原有的基学习器组合：
\begin{equation}
	H_{m}(x) = H_{m-1}(x) + \beta_{s}h(x;\theta_{s})
\end{equation}

一直训练$S$个基学习器，组合起来，便是最终的强学习器。以上便是我们的\emph{梯度提升(Gradient boosted)}的一般性框架，这个框架可以装下各种基学习算法：当我们的基学习器是决策树桩的时候，算法结构便类似于AdaBoost；当我们的基学习器是决策树的时候，变成了\emph{梯度提升决策树(Gradient boosted decision tree)}。但是GBDT的细节处理和以上还有一些不太一样，这里由于涉及到过多的细节，不再展开细述。

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{..//Plots//gbdt.pdf}
	\caption{GBDT分类器决策边界}
	\label{Fig:10}
	\vspace{-0.5em}
\end{figure}

上图是GBDT在我们的3个测试数据集上的表现。可以看到其划分的空间相较于AdaBoost分类器而言，有着明显的提升。也说明GBDT有相对较为优秀的。

\section{试验效果}
为了使读者对于以上提到的几个机器学习算法的效果有直观的认识，我们在人力资源数据集上试验了以上提到的几个算法。这里使用的是流行的开源机器学习库：\emph{Scikit-learn}，通过之前提到的特征，计算员工是否离职。对于模型的评估，这里我们使用\emph{准确率(Accuracy)}来评价分类效果。对于每一个模型，采用\emph{K折交叉校验(K-fold CV)}的方式来计算验证集误差，来评估一组参数的泛化误差。这里我们使用的是5折交叉校验，使用Scikit-learn自带的\emph{随机搜索(RandomizedSearchCV)}随机搜索100组参数，检验各组参数的效果。计算机配置为：Linux 16.04 LTS系统，硬件配置为Core i5-4200M处理器，主频2.50GHz，8G的RAM。

\begin{table}[H]
	\centering
	\label{table2}
	\begin{tabular}{|c|c|c|c|}
		\hline
		Algorithm & AccuracyCV & AccuracyTest & Searching time\\
		\hline
		Logistic Regression & 0.8595 & 0.8555 & 3.6min\\
		Support Vector Machine & 0.9666 & 0.9688 & 50.4min\\
		AdaBoost & 0.9613 & 0.9624 & 6.7min\\
		GBDT & 0.9901 & 0.9867 & 18.7min\\
		Random Forest & 0.9817 & 0.9816 & 14.4min\\
		\hline
	\end{tabular}
	\caption{人力资源数据集前4行}
\end{table}

上表是我们分类器对于人力资源数据集的准确率以及搜索参数所需要的时间。我们可以从上表看到，就计算时间而言，由于SVM需要需要计算一个$m$行$m$列的矩阵提供给算法，所以在搜索参数方面花费的时间最多；同时我们可以看到，以GBDT为代表的集成学习算法取得了出众的效果，而线性模型由于模型能力有限，并没有能够取得很好的效果。但是需要强调的是，虽然GBDT在该组数据集上取得了非常好的效果，但是并不能说明GBDT比以上的几个算法要优秀，因为正如最开始提到的一样：天下没有免费的午餐，没有任何的学习算法能够在所有任务上都做的好，这里只是说明了GBDT在人力资源数据集上的效果不错。

\section{特别致谢}
特别感谢兰州大学的刘震林同学与北京工业大学的王皓昕同学对于本文撰写提出的意见与建议。由于本人水平有限，难免会有错误或者不当之处，欢迎各位批评指正！

\bibliographystyle{unsrt}  
\bibliography{CFLD_ref} 
\end{document}